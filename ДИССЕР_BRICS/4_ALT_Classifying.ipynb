{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "32b4c95c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "from textblob import TextBlob\n",
    "import nltk\n",
    "import json\n",
    "import os\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a8533045",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Администратор\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "457fa6fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Program Files\\Python312\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ace7418849a4c9fac8a1c0a74af24bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.63G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# === Zero-Shot Тематическая классификация ===\n",
    "topic_classifier = pipeline(\"zero-shot-classification\",\n",
    "                            model=\"facebook/bart-large-mnli\",\n",
    "                            # use_safetensors=False,\n",
    "                            device=0)\n",
    "\n",
    "# === Темы-кандидаты ===\n",
    "candidate_labels = [\n",
    "    \"Politics\", \"Economy\", \"Military\", \"Health\", \"Technology\",\n",
    "    \"Energy\", \"Diplomacy\", \"Environment\", \"Conflict\", \"Elections\",\n",
    "    \"Crime\", \"Education\", \"Transport\", \"Culture\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78179741",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Каталог с JSON-файлами\n",
    "# DATA_DIR = \"./\"\n",
    "# THEMES = {\n",
    "#     \"finance\": [\"bank\", \"finance\", \"investment\", \"debt\", \"loan\", \"currency\", \"development\"],\n",
    "#     \"geopolitics\": [\"un\", \"security council\", \"usa\", \"russia\", \"china\", \"diplomacy\", \"alliances\", \"nato\"],\n",
    "#     \"technology\": [\"blockchain\", \"ai\", \"robotics\", \"technology\", \"5g\", \"nanotech\", \"innovation\", \"infrastructure\"],\n",
    "#     \"trade\": [\"exports\", \"imports\", \"trade\", \"sanctions\", \"tariffs\", \"market\", \"deal\"],\n",
    "#     \"energy\": [\"oil\", \"gas\", \"energy\", \"hydrocarbons\", \"solar\", \"renewable\", \"electricity\"],\n",
    "#     \"military\": [\"military\", \"army\", \"defense\", \"arms\", \"weapons\", \"nuclear\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14f04a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = re.sub(r\"http\\S+\", \"\", text)  # remove URLs\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25d563f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_themes(text):\n",
    "    text_lower = text.lower()\n",
    "    found_themes = []\n",
    "    for theme, keywords in THEMES.items():\n",
    "        if any(word in text_lower for word in keywords):\n",
    "            found_themes.append(theme)\n",
    "    return found_themes if found_themes else [\"other\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "166a12fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_sentiment(text):\n",
    "    blob = TextBlob(text)\n",
    "    polarity = blob.sentiment.polarity\n",
    "    if polarity > 0.1:\n",
    "        return \"positive\"\n",
    "    elif polarity < -0.1:\n",
    "        return \"negative\"\n",
    "    else:\n",
    "        return \"neutral\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de0cc140",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_file(filepath):\n",
    "    with open(filepath, \"r\", encoding=\"utf-8\") as f:\n",
    "        articles = json.load(f)\n",
    "\n",
    "    results = []\n",
    "    for article in articles:\n",
    "        full_text = article.get(\"full_content\") or article.get(\"content\") or \"\"\n",
    "        if not full_text:\n",
    "            continue\n",
    "\n",
    "        clean = clean_text(full_text)\n",
    "        sentences = nltk.sent_tokenize(clean)\n",
    "        text_joined = \" \".join(sentences)\n",
    "\n",
    "        sentiment = analyze_sentiment(text_joined)\n",
    "        themes = classify_themes(text_joined)\n",
    "\n",
    "        results.append({\n",
    "            \"title\": article.get(\"title\"),\n",
    "            \"url\": article.get(\"url\"),\n",
    "            \"sentiment\": sentiment,\n",
    "            \"themes\": themes\n",
    "        })\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f61bfb5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Обработка всех файлов в каталоге\n",
    "all_results = []\n",
    "for filename in os.listdir(DATA_DIR):\n",
    "    if filename.endswith(\"_articles.json\"):\n",
    "        filepath = os.path.join(DATA_DIR, filename)\n",
    "        country = filename.split(\"_\")[0]\n",
    "        print(f\"Processing: {country}\")\n",
    "        res = process_file(filepath)\n",
    "        for r in res:\n",
    "            r[\"country\"] = country\n",
    "        all_results.extend(res)\n",
    "\n",
    "# Сохраняем результаты\n",
    "with open(\"classified_articles.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(all_results, f, indent=4, ensure_ascii=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
